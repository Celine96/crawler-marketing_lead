"""
ì˜ì—… ë¦¬ë“œ ì´ë©”ì¼ í¬ë¡¤ëŸ¬ - Render ë°°í¬ ë²„ì „
- êµ¬ê¸€ì‹œíŠ¸ì—ì„œ íšŒì‚¬ ì •ë³´ ì½ê¸°
- ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤/ì§€ë„ì—ì„œ ì´ë©”ì¼ ê²€ìƒ‰
- íšŒì‚¬ í™ˆí˜ì´ì§€ì—ì„œ ì´ë©”ì¼ ì¶”ì¶œ
- ê²°ê³¼ë¥¼ êµ¬ê¸€ì‹œíŠ¸ì— ìë™ ì—…ë°ì´íŠ¸
"""

import gspread
from google.oauth2.service_account import Credentials
import requests
from bs4 import BeautifulSoup
import re
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import logging
import os
import json
import tempfile

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class EmailCrawler:
    def __init__(self, spreadsheet_key, credentials_json=None):
        """
        ì´ë©”ì¼ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
        
        Args:
            spreadsheet_key: êµ¬ê¸€ ì‹œíŠ¸ ID
            credentials_json: êµ¬ê¸€ ì„œë¹„ìŠ¤ ê³„ì • JSON (ë¬¸ìì—´ ë˜ëŠ” ë”•ì…”ë„ˆë¦¬)
        """
        self.spreadsheet_key = spreadsheet_key
        self.credentials_json = credentials_json
        self.sheet = None
        self.driver = None
        
        # ì´ë©”ì¼ ì •ê·œí‘œí˜„ì‹ íŒ¨í„´
        self.email_pattern = re.compile(
            r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        )
        
    def connect_google_sheet(self):
        """êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° (í™˜ê²½ ë³€ìˆ˜ ì§€ì›)"""
        try:
            scope = [
                'https://spreadsheets.google.com/feeds',
                'https://www.googleapis.com/auth/drive'
            ]
            
            # í™˜ê²½ ë³€ìˆ˜ì—ì„œ credentials ë¡œë“œ
            if isinstance(self.credentials_json, str):
                # JSON ë¬¸ìì—´ì¸ ê²½ìš°
                credentials_dict = json.loads(self.credentials_json)
            elif isinstance(self.credentials_json, dict):
                # ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
                credentials_dict = self.credentials_json
            else:
                # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš° (ë¡œì»¬ ê°œë°œìš©)
                with open(self.credentials_json, 'r') as f:
                    credentials_dict = json.load(f)
            
            creds = Credentials.from_service_account_info(
                credentials_dict,
                scopes=scope
            )
            client = gspread.authorize(creds)
            self.sheet = client.open_by_key(self.spreadsheet_key).sheet1
            logger.info("âœ… êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„±ê³µ")
            return True
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSON íŒŒì‹± ì—ëŸ¬: {e}")
            logger.error(f"ë¬¸ì œ ìœ„ì¹˜: line {e.lineno}, column {e.colno}")
            logger.error("GOOGLE_SHEETS_CREDENTIALS í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”!")
            return False
        except Exception as e:
            logger.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
            logger.error(f"ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
            import traceback
            logger.error(f"ìƒì„¸ ì •ë³´:\n{traceback.format_exc()}")
            return False
    
    def setup_selenium(self):
        """Selenium ì›¹ë“œë¼ì´ë²„ ì„¤ì • (Render í™˜ê²½ ìµœì í™”)"""
        try:
            chrome_options = Options()
            
            # Render í™˜ê²½ì„ ìœ„í•œ í•„ìˆ˜ ì˜µì…˜
            chrome_options.add_argument('--headless=new')  # ìƒˆë¡œìš´ headless ëª¨ë“œ
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--disable-software-rasterizer')
            chrome_options.add_argument('--disable-extensions')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            # ë©”ëª¨ë¦¬ ìµœì í™”
            chrome_options.add_argument('--single-process')
            chrome_options.add_argument('--disable-background-networking')
            
            # ë¡œê¹… ì¤„ì´ê¸°
            chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])
            chrome_options.add_argument('--log-level=3')
            
            # Chromium ë°”ì´ë„ˆë¦¬ ê²½ë¡œ ì„¤ì • (Render í™˜ê²½)
            chrome_binary = os.getenv('CHROME_BIN', '/usr/bin/chromium')
            chromedriver_path = os.getenv('CHROMEDRIVER_PATH', '/usr/bin/chromedriver')
            
            # Chromium ë°”ì´ë„ˆë¦¬ ìœ„ì¹˜ ì§€ì •
            if os.path.exists(chrome_binary):
                chrome_options.binary_location = chrome_binary
                logger.info(f"âœ… Chrome binary: {chrome_binary}")
            
            # ChromeDriver ì„œë¹„ìŠ¤ ì„¤ì •
            try:
                if os.path.exists(chromedriver_path):
                    service = Service(chromedriver_path)
                    logger.info(f"âœ… ChromeDriver: {chromedriver_path}")
                elif os.path.exists('/usr/local/bin/chromedriver'):
                    service = Service('/usr/local/bin/chromedriver')
                    logger.info("âœ… ChromeDriver: /usr/local/bin/chromedriver")
                else:
                    # fallback: webdriver-manager ì‚¬ìš©
                    from webdriver_manager.chrome import ChromeDriverManager
                    service = Service(ChromeDriverManager().install())
                    logger.info("âœ… ChromeDriver: webdriver-manager")
            except:
                service = Service()  # ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
                logger.info("âœ… ChromeDriver: default path")
            
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            self.driver.set_page_load_timeout(30)
            
            logger.info("âœ… Selenium ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"âŒ Selenium ì„¤ì • ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False
    
    def search_naver_place(self, company_name):
        """
        ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤/ì§€ë„ì—ì„œ íšŒì‚¬ ì •ë³´ ê²€ìƒ‰
        
        Args:
            company_name: íšŒì‚¬ëª…
            
        Returns:
            dict: {email, homepage, phone}
        """
        try:
            search_url = f"https://search.naver.com/search.naver?query={company_name}"
            self.driver.get(search_url)
            time.sleep(2)
            
            result = {
                'email': None,
                'homepage': None,
                'phone': None
            }
            
            # í”Œë ˆì´ìŠ¤ ì •ë³´ ì°¾ê¸°
            try:
                # ì „í™”ë²ˆí˜¸
                phone_elements = self.driver.find_elements(By.CSS_SELECTOR, '.tel, .phone, [class*="tel"]')
                if phone_elements:
                    result['phone'] = phone_elements[0].text.strip()
                
                # í™ˆí˜ì´ì§€ URL
                homepage_elements = self.driver.find_elements(By.CSS_SELECTOR, 'a[href*="http"]')
                for elem in homepage_elements:
                    href = elem.get_attribute('href')
                    if href and 'naver.com' not in href and 'google.com' not in href:
                        result['homepage'] = href
                        break
                
                # í˜ì´ì§€ ì†ŒìŠ¤ì—ì„œ ì´ë©”ì¼ ì¶”ì¶œ
                page_source = self.driver.page_source
                emails = self.email_pattern.findall(page_source)
                
                # ë„¤ì´ë²„ ê´€ë ¨ ì´ë©”ì¼ ì œì™¸
                valid_emails = [
                    email for email in emails 
                    if 'naver.com' not in email and 'google.com' not in email
                ]
                
                if valid_emails:
                    result['email'] = valid_emails[0]
                
            except Exception as e:
                logger.warning(f"í”Œë ˆì´ìŠ¤ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            
            return result
            
        except Exception as e:
            logger.error(f"ë„¤ì´ë²„ ê²€ìƒ‰ ì‹¤íŒ¨ ({company_name}): {e}")
            return {'email': None, 'homepage': None, 'phone': None}
    
    def extract_email_from_website(self, url):
        """
        íšŒì‚¬ í™ˆí˜ì´ì§€ì—ì„œ ì´ë©”ì¼ ì¶”ì¶œ
        
        Args:
            url: í™ˆí˜ì´ì§€ URL
            
        Returns:
            str: ì´ë©”ì¼ ì£¼ì†Œ ë˜ëŠ” None
        """
        try:
            if not url:
                return None
            
            # URL ì •ê·œí™”
            if not url.startswith('http'):
                url = 'http://' + url
            
            self.driver.get(url)
            time.sleep(2)
            
            # ì—°ë½ì²˜/Contact í˜ì´ì§€ ì°¾ê¸°
            contact_links = self.driver.find_elements(
                By.XPATH, 
                "//a[contains(text(), 'ì—°ë½') or contains(text(), 'Contact') or contains(text(), 'íšŒì‚¬ì†Œê°œ')]"
            )
            
            if contact_links:
                contact_links[0].click()
                time.sleep(2)
            
            # í˜ì´ì§€ì—ì„œ ì´ë©”ì¼ ì¶”ì¶œ
            page_source = self.driver.page_source
            emails = self.email_pattern.findall(page_source)
            
            # ìœ íš¨í•œ ì´ë©”ì¼ í•„í„°ë§ (info@, ceo@, contact@ ë“± ìš°ì„ )
            priority_keywords = ['ceo', 'info', 'contact', 'admin', 'master']
            
            for keyword in priority_keywords:
                for email in emails:
                    if keyword in email.lower():
                        return email
            
            # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì´ë©”ì¼ ë°˜í™˜
            if emails:
                return emails[0]
            
            return None
            
        except Exception as e:
            logger.warning(f"í™ˆí˜ì´ì§€ ì´ë©”ì¼ ì¶”ì¶œ ì‹¤íŒ¨ ({url}): {e}")
            return None
    
    def find_email(self, company_name, representative=None):
        """
        íšŒì‚¬ ì´ë©”ì¼ ì°¾ê¸° (ë„¤ì´ë²„ + í™ˆí˜ì´ì§€)
        
        Args:
            company_name: íšŒì‚¬ëª…
            representative: ëŒ€í‘œìëª… (ì„ íƒ)
            
        Returns:
            dict: {email, source, confidence}
        """
        logger.info(f"ğŸ” ê²€ìƒ‰ ì‹œì‘: {company_name}")
        
        result = {
            'email': None,
            'source': None,
            'confidence': 'LOW'
        }
        
        # 1ë‹¨ê³„: ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤/ì§€ë„ ê²€ìƒ‰
        naver_result = self.search_naver_place(company_name)
        
        if naver_result['email']:
            result['email'] = naver_result['email']
            result['source'] = 'ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤'
            result['confidence'] = 'HIGH'
            logger.info(f"âœ… ë„¤ì´ë²„ì—ì„œ ì´ë©”ì¼ ë°œê²¬: {result['email']}")
            return result
        
        # 2ë‹¨ê³„: í™ˆí˜ì´ì§€ì—ì„œ ì´ë©”ì¼ ì¶”ì¶œ
        if naver_result['homepage']:
            website_email = self.extract_email_from_website(naver_result['homepage'])
            if website_email:
                result['email'] = website_email
                result['source'] = 'íšŒì‚¬ í™ˆí˜ì´ì§€'
                result['confidence'] = 'MEDIUM'
                logger.info(f"âœ… í™ˆí˜ì´ì§€ì—ì„œ ì´ë©”ì¼ ë°œê²¬: {result['email']}")
                return result
        
        logger.warning(f"âš ï¸ ì´ë©”ì¼ì„ ì°¾ì§€ ëª»í•¨: {company_name}")
        return result
    
    def add_email_column(self):
        """êµ¬ê¸€ì‹œíŠ¸ì— ì´ë©”ì¼ ì»¬ëŸ¼ ì¶”ê°€"""
        try:
            # í˜„ì¬ í—¤ë” ê°€ì ¸ì˜¤ê¸°
            headers = self.sheet.row_values(1)
            
            # ì´ë¯¸ ì´ë©”ì¼ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
            if 'ëŒ€í‘œì´ë©”ì¼(ìë™ìˆ˜ì§‘)' in headers:
                logger.info("ì´ë©”ì¼ ì»¬ëŸ¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤")
                return headers.index('ëŒ€í‘œì´ë©”ì¼(ìë™ìˆ˜ì§‘)') + 1
            
            # ìƒˆ ì»¬ëŸ¼ ì¶”ê°€ (I ì»¬ëŸ¼ ë‹¤ìŒ)
            new_col_index = len(headers) + 1
            self.sheet.update_cell(1, new_col_index, 'ëŒ€í‘œì´ë©”ì¼(ìë™ìˆ˜ì§‘)')
            self.sheet.update_cell(1, new_col_index + 1, 'ìˆ˜ì§‘ì¶œì²˜')
            self.sheet.update_cell(1, new_col_index + 2, 'ì‹ ë¢°ë„')
            
            logger.info(f"âœ… ì´ë©”ì¼ ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ (ì»¬ëŸ¼ {new_col_index})")
            return new_col_index
            
        except Exception as e:
            logger.error(f"âŒ ì»¬ëŸ¼ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return None
    
    def crawl_all_companies(self, start_row=2, end_row=None):
        """
        ì „ì²´ íšŒì‚¬ ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§
        
        Args:
            start_row: ì‹œì‘ í–‰ (ê¸°ë³¸ê°’: 2, í—¤ë” ì œì™¸)
            end_row: ì¢…ë£Œ í–‰ (Noneì´ë©´ ì „ì²´)
        """
        try:
            # ì´ë©”ì¼ ì»¬ëŸ¼ ì¶”ê°€
            email_col = self.add_email_column()
            if not email_col:
                return
            
            # ì „ì²´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            all_data = self.sheet.get_all_values()
            
            if end_row is None:
                end_row = len(all_data)
            
            total_count = end_row - start_row + 1
            success_count = 0
            
            logger.info(f"ğŸ“Š ì´ {total_count}ê°œ íšŒì‚¬ í¬ë¡¤ë§ ì‹œì‘")
            
            # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë”œë ˆì´ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
            crawl_delay = int(os.getenv('CRAWL_DELAY', '3'))
            
            for idx in range(start_row - 1, end_row):
                row_num = idx + 1
                row_data = all_data[idx]
                
                # íšŒì‚¬ëª… (Bì—´)
                company_name = row_data[1] if len(row_data) > 1 else None
                # ëŒ€í‘œìëª… (Cì—´)
                representative = row_data[2] if len(row_data) > 2 else None
                
                if not company_name:
                    continue
                
                logger.info(f"\n[{row_num - 1}/{total_count}] ì²˜ë¦¬ ì¤‘: {company_name}")
                
                # ì´ë©”ì¼ ê²€ìƒ‰
                result = self.find_email(company_name, representative)
                
                # ê²°ê³¼ ì—…ë°ì´íŠ¸
                if result['email']:
                    self.sheet.update_cell(row_num, email_col, result['email'])
                    self.sheet.update_cell(row_num, email_col + 1, result['source'])
                    self.sheet.update_cell(row_num, email_col + 2, result['confidence'])
                    success_count += 1
                else:
                    self.sheet.update_cell(row_num, email_col, 'ë¯¸ë°œê²¬')
                    self.sheet.update_cell(row_num, email_col + 2, 'NONE')
                
                # API ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°
                time.sleep(crawl_delay)
            
            logger.info(f"\nâœ… í¬ë¡¤ë§ ì™„ë£Œ!")
            logger.info(f"ğŸ“Š ì„±ê³µ: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)")
            
        except Exception as e:
            logger.error(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.driver:
            self.driver.quit()
            logger.info("âœ… ë¸Œë¼ìš°ì € ì¢…ë£Œ")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©"""
    
    try:
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì • ì½ê¸°
        SPREADSHEET_KEY = os.getenv('SPREADSHEET_KEY')
        CREDENTIALS_JSON = os.getenv('GOOGLE_SHEETS_CREDENTIALS')
        START_ROW = int(os.getenv('START_ROW', '2'))
        
        if not SPREADSHEET_KEY:
            raise ValueError("SPREADSHEET_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        if not CREDENTIALS_JSON:
            raise ValueError("GOOGLE_SHEETS_CREDENTIALS í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        logger.info("=" * 60)
        logger.info("ğŸš€ ì´ë©”ì¼ í¬ë¡¤ëŸ¬ ì‹œì‘ (Render ëª¨ë“œ)")
        logger.info("=" * 60)
        logger.info(f"ğŸ“Š êµ¬ê¸€ ì‹œíŠ¸ ID: {SPREADSHEET_KEY[:20]}...")
        logger.info(f"â±ï¸  í¬ë¡¤ë§ ë”œë ˆì´: {os.getenv('CRAWL_DELAY', '3')}ì´ˆ")
        logger.info("=" * 60)
        
        # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
        crawler = EmailCrawler(
            spreadsheet_key=SPREADSHEET_KEY,
            credentials_json=CREDENTIALS_JSON
        )
        
        # êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
        if not crawler.connect_google_sheet():
            logger.error("êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        # Selenium ì„¤ì •
        if not crawler.setup_selenium():
            logger.error("Selenium ì„¤ì • ì‹¤íŒ¨. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        # ì „ì²´ í¬ë¡¤ë§ ì‹¤í–‰
        logger.info("\nğŸ“ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n")
        crawler.crawl_all_companies(start_row=START_ROW)
        
        logger.info("\n" + "=" * 60)
        logger.info("âœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        logger.info("=" * 60)
        
    except KeyboardInterrupt:
        logger.info("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤")
    except Exception as e:
        logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise
    finally:
        if 'crawler' in locals():
            crawler.close()


if __name__ == "__main__":
    main()
