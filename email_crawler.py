"""
ì˜ì—… ë¦¬ë“œ ì´ë©”ì¼ í¬ë¡¤ëŸ¬
- êµ¬ê¸€ì‹œíŠ¸ì—ì„œ íšŒì‚¬ ì •ë³´ ì½ê¸°
- ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤/ì§€ë„ì—ì„œ ì´ë©”ì¼ ê²€ìƒ‰
- íšŒì‚¬ í™ˆí˜ì´ì§€ì—ì„œ ì´ë©”ì¼ ì¶”ì¶œ
- ê²°ê³¼ë¥¼ êµ¬ê¸€ì‹œíŠ¸ì— ìë™ ì—…ë°ì´íŠ¸
"""

import gspread
from google.oauth2.service_account import Credentials
import requests
from bs4 import BeautifulSoup
import re
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class EmailCrawler:
    def __init__(self, spreadsheet_key, credentials_file):
        """
        ì´ë©”ì¼ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
        
        Args:
            spreadsheet_key: êµ¬ê¸€ ì‹œíŠ¸ ID
            credentials_file: êµ¬ê¸€ ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ íŒŒì¼ ê²½ë¡œ
        """
        self.spreadsheet_key = spreadsheet_key
        self.credentials_file = credentials_file
        self.sheet = None
        self.driver = None
        
        # ì´ë©”ì¼ ì •ê·œí‘œí˜„ì‹ íŒ¨í„´
        self.email_pattern = re.compile(
            r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        )
        
    def connect_google_sheet(self):
        """êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°"""
        try:
            scope = [
                'https://spreadsheets.google.com/feeds',
                'https://www.googleapis.com/auth/drive'
            ]
            
            creds = Credentials.from_service_account_file(
                self.credentials_file, 
                scopes=scope
            )
            client = gspread.authorize(creds)
            self.sheet = client.open_by_key(self.spreadsheet_key).sheet1
            logger.info("âœ… êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„±ê³µ")
            return True
        except Exception as e:
            logger.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def setup_selenium(self):
        """Selenium ì›¹ë“œë¼ì´ë²„ ì„¤ì •"""
        try:
            from selenium.webdriver.chrome.service import Service
            from webdriver_manager.chrome import ChromeDriverManager
            
            chrome_options = Options()
            chrome_options.add_argument('--headless')  # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            # webdriver-managerë¡œ ìë™ ì„¤ì¹˜
            service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            
            logger.info("âœ… Selenium ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"âŒ Selenium ì„¤ì • ì‹¤íŒ¨: {e}")
            return False
    
    def search_naver_place(self, company_name):
        """
        ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤/ì§€ë„ì—ì„œ íšŒì‚¬ ì •ë³´ ê²€ìƒ‰
        
        Args:
            company_name: íšŒì‚¬ëª…
            
        Returns:
            dict: {email, homepage, phone}
        """
        try:
            search_url = f"https://search.naver.com/search.naver?query={company_name}"
            self.driver.get(search_url)
            time.sleep(2)
            
            result = {
                'email': None,
                'homepage': None,
                'phone': None
            }
            
            # í”Œë ˆì´ìŠ¤ ì •ë³´ ì°¾ê¸°
            try:
                # ì „í™”ë²ˆí˜¸
                phone_elements = self.driver.find_elements(By.CSS_SELECTOR, '.tel, .phone, [class*="tel"]')
                if phone_elements:
                    result['phone'] = phone_elements[0].text.strip()
                
                # í™ˆí˜ì´ì§€ URL
                homepage_elements = self.driver.find_elements(By.CSS_SELECTOR, 'a[href*="http"]')
                for elem in homepage_elements:
                    href = elem.get_attribute('href')
                    if href and 'naver.com' not in href and 'google.com' not in href:
                        result['homepage'] = href
                        break
                
                # í˜ì´ì§€ ì†ŒìŠ¤ì—ì„œ ì´ë©”ì¼ ì¶”ì¶œ
                page_source = self.driver.page_source
                emails = self.email_pattern.findall(page_source)
                
                # ë„¤ì´ë²„ ê´€ë ¨ ì´ë©”ì¼ ì œì™¸
                valid_emails = [
                    email for email in emails 
                    if 'naver.com' not in email and 'google.com' not in email
                ]
                
                if valid_emails:
                    result['email'] = valid_emails[0]
                
            except Exception as e:
                logger.warning(f"í”Œë ˆì´ìŠ¤ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            
            return result
            
        except Exception as e:
            logger.error(f"ë„¤ì´ë²„ ê²€ìƒ‰ ì‹¤íŒ¨ ({company_name}): {e}")
            return {'email': None, 'homepage': None, 'phone': None}
    
    def extract_email_from_website(self, url):
        """
        íšŒì‚¬ í™ˆí˜ì´ì§€ì—ì„œ ì´ë©”ì¼ ì¶”ì¶œ
        
        Args:
            url: í™ˆí˜ì´ì§€ URL
            
        Returns:
            str: ì´ë©”ì¼ ì£¼ì†Œ ë˜ëŠ” None
        """
        try:
            if not url:
                return None
            
            # URL ì •ê·œí™”
            if not url.startswith('http'):
                url = 'http://' + url
            
            self.driver.get(url)
            time.sleep(2)
            
            # ì—°ë½ì²˜/Contact í˜ì´ì§€ ì°¾ê¸°
            contact_links = self.driver.find_elements(
                By.XPATH, 
                "//a[contains(text(), 'ì—°ë½') or contains(text(), 'Contact') or contains(text(), 'íšŒì‚¬ì†Œê°œ')]"
            )
            
            if contact_links:
                contact_links[0].click()
                time.sleep(2)
            
            # í˜ì´ì§€ì—ì„œ ì´ë©”ì¼ ì¶”ì¶œ
            page_source = self.driver.page_source
            emails = self.email_pattern.findall(page_source)
            
            # ìœ íš¨í•œ ì´ë©”ì¼ í•„í„°ë§ (info@, ceo@, contact@ ë“± ìš°ì„ )
            priority_keywords = ['ceo', 'info', 'contact', 'admin', 'master']
            
            for keyword in priority_keywords:
                for email in emails:
                    if keyword in email.lower():
                        return email
            
            # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì´ë©”ì¼ ë°˜í™˜
            if emails:
                return emails[0]
            
            return None
            
        except Exception as e:
            logger.warning(f"í™ˆí˜ì´ì§€ ì´ë©”ì¼ ì¶”ì¶œ ì‹¤íŒ¨ ({url}): {e}")
            return None
    
    def find_email(self, company_name, representative=None):
        """
        íšŒì‚¬ ì´ë©”ì¼ ì°¾ê¸° (ë„¤ì´ë²„ + í™ˆí˜ì´ì§€)
        
        Args:
            company_name: íšŒì‚¬ëª…
            representative: ëŒ€í‘œìëª… (ì„ íƒ)
            
        Returns:
            dict: {email, source, confidence}
        """
        logger.info(f"ğŸ” ê²€ìƒ‰ ì‹œì‘: {company_name}")
        
        result = {
            'email': None,
            'source': None,
            'confidence': 'LOW'
        }
        
        # 1ë‹¨ê³„: ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤/ì§€ë„ ê²€ìƒ‰
        naver_result = self.search_naver_place(company_name)
        
        if naver_result['email']:
            result['email'] = naver_result['email']
            result['source'] = 'ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤'
            result['confidence'] = 'HIGH'
            logger.info(f"âœ… ë„¤ì´ë²„ì—ì„œ ì´ë©”ì¼ ë°œê²¬: {result['email']}")
            return result
        
        # 2ë‹¨ê³„: í™ˆí˜ì´ì§€ì—ì„œ ì´ë©”ì¼ ì¶”ì¶œ
        if naver_result['homepage']:
            website_email = self.extract_email_from_website(naver_result['homepage'])
            if website_email:
                result['email'] = website_email
                result['source'] = 'íšŒì‚¬ í™ˆí˜ì´ì§€'
                result['confidence'] = 'MEDIUM'
                logger.info(f"âœ… í™ˆí˜ì´ì§€ì—ì„œ ì´ë©”ì¼ ë°œê²¬: {result['email']}")
                return result
        
        logger.warning(f"âš ï¸ ì´ë©”ì¼ì„ ì°¾ì§€ ëª»í•¨: {company_name}")
        return result
    
    def add_email_column(self):
        """êµ¬ê¸€ì‹œíŠ¸ì— ì´ë©”ì¼ ì»¬ëŸ¼ ì¶”ê°€"""
        try:
            # í˜„ì¬ í—¤ë” ê°€ì ¸ì˜¤ê¸°
            headers = self.sheet.row_values(1)
            
            # ì´ë¯¸ ì´ë©”ì¼ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
            if 'ëŒ€í‘œì´ë©”ì¼(ìë™ìˆ˜ì§‘)' in headers:
                logger.info("ì´ë©”ì¼ ì»¬ëŸ¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤")
                return headers.index('ëŒ€í‘œì´ë©”ì¼(ìë™ìˆ˜ì§‘)') + 1
            
            # ìƒˆ ì»¬ëŸ¼ ì¶”ê°€ (I ì»¬ëŸ¼ ë‹¤ìŒ)
            new_col_index = len(headers) + 1
            self.sheet.update_cell(1, new_col_index, 'ëŒ€í‘œì´ë©”ì¼(ìë™ìˆ˜ì§‘)')
            self.sheet.update_cell(1, new_col_index + 1, 'ìˆ˜ì§‘ì¶œì²˜')
            self.sheet.update_cell(1, new_col_index + 2, 'ì‹ ë¢°ë„')
            
            logger.info(f"âœ… ì´ë©”ì¼ ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ (ì»¬ëŸ¼ {new_col_index})")
            return new_col_index
            
        except Exception as e:
            logger.error(f"âŒ ì»¬ëŸ¼ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return None
    
    def crawl_all_companies(self, start_row=2, end_row=None):
        """
        ì „ì²´ íšŒì‚¬ ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§
        
        Args:
            start_row: ì‹œì‘ í–‰ (ê¸°ë³¸ê°’: 2, í—¤ë” ì œì™¸)
            end_row: ì¢…ë£Œ í–‰ (Noneì´ë©´ ì „ì²´)
        """
        try:
            # ì´ë©”ì¼ ì»¬ëŸ¼ ì¶”ê°€
            email_col = self.add_email_column()
            if not email_col:
                return
            
            # ì „ì²´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            all_data = self.sheet.get_all_values()
            
            if end_row is None:
                end_row = len(all_data)
            
            total_count = end_row - start_row + 1
            success_count = 0
            
            logger.info(f"ğŸ“Š ì´ {total_count}ê°œ íšŒì‚¬ í¬ë¡¤ë§ ì‹œì‘")
            
            for idx in range(start_row - 1, end_row):
                row_num = idx + 1
                row_data = all_data[idx]
                
                # íšŒì‚¬ëª… (Bì—´)
                company_name = row_data[1] if len(row_data) > 1 else None
                # ëŒ€í‘œìëª… (Cì—´)
                representative = row_data[2] if len(row_data) > 2 else None
                
                if not company_name:
                    continue
                
                logger.info(f"\n[{row_num - 1}/{total_count}] ì²˜ë¦¬ ì¤‘: {company_name}")
                
                # ì´ë©”ì¼ ê²€ìƒ‰
                result = self.find_email(company_name, representative)
                
                # ê²°ê³¼ ì—…ë°ì´íŠ¸
                if result['email']:
                    self.sheet.update_cell(row_num, email_col, result['email'])
                    self.sheet.update_cell(row_num, email_col + 1, result['source'])
                    self.sheet.update_cell(row_num, email_col + 2, result['confidence'])
                    success_count += 1
                else:
                    self.sheet.update_cell(row_num, email_col, 'ë¯¸ë°œê²¬')
                    self.sheet.update_cell(row_num, email_col + 2, 'NONE')
                
                # API ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°
                time.sleep(3)
            
            logger.info(f"\nâœ… í¬ë¡¤ë§ ì™„ë£Œ!")
            logger.info(f"ğŸ“Š ì„±ê³µ: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)")
            
        except Exception as e:
            logger.error(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.driver:
            self.driver.quit()
            logger.info("âœ… ë¸Œë¼ìš°ì € ì¢…ë£Œ")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    try:
        from config import Config
        
        # ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬
        Config.validate()
        
        logger.info("=" * 60)
        logger.info("ğŸš€ ì´ë©”ì¼ í¬ë¡¤ëŸ¬ ì‹œì‘")
        logger.info("=" * 60)
        logger.info(f"ğŸ“Š êµ¬ê¸€ ì‹œíŠ¸ ID: {Config.SPREADSHEET_KEY[:20]}...")
        logger.info(f"ğŸ”‘ ì¸ì¦ íŒŒì¼: {Config.CREDENTIALS_FILE}")
        logger.info(f"â±ï¸  í¬ë¡¤ë§ ë”œë ˆì´: {Config.CRAWL_DELAY}ì´ˆ")
        logger.info("=" * 60)
        
        # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
        crawler = EmailCrawler(
            spreadsheet_key=Config.SPREADSHEET_KEY,
            credentials_file=Config.CREDENTIALS_FILE
        )
        
        # êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
        if not crawler.connect_google_sheet():
            logger.error("êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        # Selenium ì„¤ì •
        if not crawler.setup_selenium():
            logger.error("Selenium ì„¤ì • ì‹¤íŒ¨. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        # ì „ì²´ í¬ë¡¤ë§ ì‹¤í–‰
        logger.info("\nğŸ“ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n")
        crawler.crawl_all_companies(start_row=Config.START_ROW)
        
        logger.info("\n" + "=" * 60)
        logger.info("âœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        logger.info("=" * 60)
        
    except KeyboardInterrupt:
        logger.info("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤")
    except FileNotFoundError as e:
        logger.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        logger.error("ğŸ’¡ .env íŒŒì¼ê³¼ credentials.json íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”")
    except ValueError as e:
        logger.error(f"âŒ ì„¤ì • ì˜¤ë¥˜: {e}")
        logger.error("ğŸ’¡ .env íŒŒì¼ì˜ SPREADSHEET_KEYë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”")
    except Exception as e:
        logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        logger.error(traceback.format_exc())
    finally:
        if 'crawler' in locals():
            crawler.close()


if __name__ == "__main__":
    main()
